<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>Hao Hu</title>
  <meta name="description" content="Hao Hu's homepage">

  <link href="./css/github-light.css" rel="stylesheet">
  <link href="./css/style.css" rel="stylesheet">
  <style> 
    .visit{text-align:center} 
    </style> 
</head>
<body>
  <div class="container">
    <header>
      <h1>Hao Hu</h1>
      <img src="./assets/huhao.jpg" style="width:230px;"><br />
      <p>
        <br/>
        Master's Student in Computer Science <br />
        IIIS, Tsinghua University <br />
        Beijing, China
        <br/>
        <a href="mailto: hu-h19@mails.tsinghua.edu.cn"> <img src="./assets/email_icon.png" alt="Email" style="width:19px;border:0;"> Email </a> <br/> 
        <a href="https://github.com/mousehu"> <img src="./assets/github.png" alt=" Github" style="width:16px;height:15px;border:0;"> Github </a> <br/>
        <a href="https://www.linkedin.com/in/hao-hu-tsinghua/"> <img src="./assets/linkedin3.png" alt=" Linkedin" style="width:16px;height:15px;border:0;"> Linkedin </a> <br/>
        <a href="./assets/resume.pdf"> <img src="./assets/cv_icon.png" alt=" CV" style="width:14px;height:14px;border:0;"> CV </a><br /><br/>
    </header>

    <section class="content">
      <h3>About</h3>
      <p>
  			I currently a Master's student working with <a href="http://people.iiis.tsinghua.edu.cn/~zhang/"> Prof. Chongjie Zhang </a> at <a href="https://iiis.tsinghua.edu.cn/en/"> 
        Institute for Interdisciplinary Information Sciences</a>, Tsinghua University, headed by <a href="https://iiis.tsinghua.edu.cn/yao/"> Prof. Andrew Yao</a>. My primary research 
        goal is to develop innovative models and methods to enable sample-efficient and generalizable reinforcement learning.
        My research interests include episodic control, zero-shot reinforcement learning, and offline reinforcement learning.
      </p>
      
      <h3>Publications and Preprints</h3>
      <ul class="sparse-list">
         <!-- <li>
          <span class="underline">Tonghan Wang</span>, Tarun Gupta, Anuj Mahajan, Bei Peng, Shimon Whiteson, and Chongjie Zhang <br />
          <b style=color:#66ccff;">RODE: Learning Roles to Decompose Multi-Agent Tasks.</b> <br />
          <b>ICLR 2021: </b> International Conference on Learning Representations <br/>
          <a href="https://arxiv.org/abs/2010.01523"> PDF </a> | <a href="https://sites.google.com/view/rode-marl"> Video </a> | <a href="https://github.com/TonghanWang/RODE"> Code </a>
        </li> -->
        <li>
          <b>Generalizable Episodic Memory for Deep Reinforcement Learning </b> <br />
          <span class="underline">Hao Hu</span>, Jianing Ye, Zhizhou Ren, Guangxiang Zhu, and Chongjie Zhang <br />
          <i>International Conference on Machine Learning (ICML), 2021</i><br/>
          <a href="https://arxiv.org/abs/2103.06469"> PDF </a> | <a href="https://github.com/MouseHu/GEM"> Code </a>
        </li>
        <li>
          <b>MetaCURE: Meta Reinforcement Learning with Empowerment-Driven Exploration</b> <br />
          Jin Zhang*, Jianhao Wang*, <span class="underline">Hao Hu</span>, Tong Chen, Yingfeng Chen, Changjie Fan, Chongjie Zhang <br />
          <i>International Conference on Machine Learning (ICML), 2021</i><br/>
          <a href="https://arxiv.org/abs/2006.08170"> PDF </a> | <a href="https://github.com/NagisaZj/MetaCURE-Public"> Code </a>
        </li>
        <li>
          <b>On the Estimation Bias in Double Q-Learning</b> <br />
          Zhizhou Ren, Guangxiang Zhu, <span class="underline">Hao Hu</span>, Beining Han, Jianglun Chen, Chongjie Zhang <br />
          <i>Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS), 2021</i> <br/>
          <a href="https://arxiv.org/pdf/2109.14419.pdf"> PDF </a>
        </li>
        <li>
          <b>Offline Reinforcement Learning with Value-based Episodic Memory</b> <br />
          Xiaoteng Ma*, Yiqin Yang*, <span class="underline">Hao Hu*</span>, Qihan Liu, Jun Yang, Chongjie Zhang, Qianchuan Zhao, Bin Liang <br />
          <i>Tenth International Conference on Learning Representations (ICLR), 2022</i> <br/>
          <a href="https://arxiv.org/pdf/2110.09796.pdf"> PDF </a>
        </li>
      </ul>

                                                                                                                          
      <h3> Experience </h3>
      <ul>
        <li><b> Teaching Assistant </b> <br />
          Artificial Intelligence: Principles and Techniques, Fall, 2020 </li>
          Artificial Intelligence: Principles and Techniques, Fall, 2021 </li>
          Deep Reinforcement Learning, Spring, 2022 </li>
        <li><b> Engineering Intern </b> <br />
          Microsoft STCA, News & Relevance Team, Jun. 2018 - Sept. 2018
        </li>
        <li><b> Research Intern </b> <br />
          <a href="https://www.pkuvmc.com/"> Vision and Media Computing Group </a>, Peking University, Nov. 2017- Jun. 2018
        </li>
      </ul>

      <h3>Education</h3>
      <ul>
        <li>
          <b> M.Sc. in Computer Science (GPA: 3.96 / 4.00) </b> <br/>
          IIIS, Tsinghua University @ Beijing, China, 2019 -- Present <br/>
          Deep Reinforcement Learning
        </li>                                                                                                                  
        <li>
          <b> B.Sc. in Theoretical and Applied Mechanics (GPA: 3.73 / 4.00) </b> <br/>
          Peking University @ Beijing, China, 2015 -- 2019 <br/>
          Double major: Computer Science and Technology<br/>
          Thesis: The Convergence of Momentum Policy Prediction Method
          and Its Application in Multi-agent Reinforcement Learning
        </li>
      </ul>
      <h3>On-going Projects</h3>
      <ul>
        <li>
          <b> Episodic Control with Skills</b> <br/>
          Use episodic memory for skill storage and retrival, enabling efficient exploration and learning with skills <br/>
        </li>                                                                                                                  
        <li>
          <b> Zero-shot Reinforcement Learning with Semantic World Models </b> <br/>
          Use semantic world model to enable zero-shot transfer and combinatorial generalization of skills to new tasks <br/>
        </li>
        <!-- <li>
          <b> Lightning RL: A light-weight, auto-tuning and distributed RL framework </b> <br/>
          See <a href="https://github.com/MouseHu/RLLightning"> Github Link </a>  <br/>
        </li> -->
      </ul>
      <div class="visit">
        <!-- <a href="https://clustrmaps.com/site/1bh1k" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=hNvBXX4UmAGYx0olALmdhFqEyvFSp289uxN0uJasOqk&cl=ffffff"></a> -->
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=hNvBXX4UmAGYx0olALmdhFqEyvFSp289uxN0uJasOqk"></script>
      </div>
      <!-- \section{On-going Projects}
\begin{itemize}
    \item Episodic Skill Control\par
    \textit{blah blah}
    \item Zero-shot Reinforcement Learning with senmantic world models\par
    \textit{blah blah}
    \item Lightning RL: A light-weight, auto-tuning and distributed RL framework\par
    \textit{blah blah}
\end{itemize} -->
    </section>
  </div>
</body>
</html>
